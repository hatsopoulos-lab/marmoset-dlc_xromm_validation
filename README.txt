This README.txt file was generated on 2022-01-12 by Dalton Moore. 
It is a copy of the README file attached to the dataset stored at https://doi.org/10.5061/dryad.d7wm37q2z.
See METHODOLOGICAL INFORMATION for information on how to use the code. Files mentioned will need to be pulled
from Dryad for most of the code to run properly.

GENERAL INFORMATION

1. Title of Dataset: DLC+Anipose Validation Data

2. Author Information
	A. Principal Investigator Contact Information
		Name: Nicho Hatsopoulos
		Institution: University of Chicago
		Email: nicho@uchicago.edu

	B. Primary Contact for Questions About Data
		Name: Dalton Moore
		Institution: University of Chicago
		Email: daltonm@uchicago.edu 
		
3. Date of data collection: 2019_04_14 and 2019_04_15 

4. Geographic location of data collection: XROMM Facility, University of Chicago, Chicago, IL, USA 

5. Information about funding sources that supported the collection of the data: 
	A. National Institutes of Health R01NS104898
	B. National Institutes of Health 1F31NS118950-01
	C. National Science Foundation   MRI1338036
	D. National Science Foundation   MRI1626552


SHARING/ACCESS INFORMATION

1. Licenses/restrictions placed on the data: None

2. Links to publications that cite or use the data: Journal of Experimental Biology LINK TO BE ADDED  

3. Recommended citation for this dataset: Please cite the paper linked above

DATA & FILE OVERVIEW

1. File List: 
	
	anipose_files (contains raw files that go into anipose analysis and processed files generated by anipose)
		|- anipose_on_iteration_1_trainFrac_85_shuffle_3_snapshotindex_23_param_vals_20_5_6_2_8_pt45 
		       Contains all input and output files from anipose for the dataset using the best parameter set, 
			   except raw videos. See anipose docs for explaination of each subfolder.   
		|- parameter_sweep
		       Contains anipose results from each parameter set  
		|- starter_files
		       Contains videos-raw, pose-2d, and calibration files. Which can be ported wherever needed 
			   for running anipose. 
		|- training_set_size_iteration0
		       Contains anipose outputs from the best parameter set run on iteration-0 DLC networks
		|- training_set_size_iteration1
		       Contains anipose outputs from the best parameter set run on iteration-0 DLC networks
			   
	deeplabcut_files (contains the main deeplabcut project files and secondary related files)
	    |- combined_dlc_xromm_validation-Dalton-2021-08-28
		  Contains DLC project files. See DLC documentation for further explanation of data stored here.
            |- dlc_files_for_secondary_analysis
                  Contains files used for assessment of human labeling error, etc.
            |- calibration images
                  Contains visible light calibration images for each session	
		
	results_presented_in_manuscript (contains the results that are presented in the paper linked above)
        |- hdf_versions
               Versions of all data in hdf format saved as .h5 files. Converted from pickle files. 
        |- pickle_version
               Versions of all data in pickle format, as originally saved.
			   
	xromm_files (Contains raw xromm files and trajectories saved from XMALab)
              The data contained in the folders are the basic data needed to run XMALab on the data. 
              validation_trajectories holds the csv files of each trajectory that DLC is compared to   		

        python_code (uploaded as individual software files)
	    Will explain how to use each script in the Methodological Information section

METHODOLOGICAL INFORMATION

1. Description of methods used for collection/generation of data: 
    See paper linked above for detailed methods.

2. Methods for processing the data: 

	Before reproducing any of the results:
		1. Download the entire set of files
		2. For each relevant python script change the project_path variable to the folder in 
		   which this dataset was downloaded. Relevant scripts are:
		   A. collect_uncombined_sweep_results.py
		   B. compute_statistics_and_secondary_results.py
		   C. convert_pickle_to_h5_and_csv.py
		   D. dlc_anipose_and_xromm_trajectory_and_secondary_data_processing_and_analysis.py
		   E. load_hdf_to_original_formats.py
		   F. produce_figures.py
	
	To reproduce figures:
		1. run produce_figures.py 
		2. Find the figures in results_presented_in_manuscript/figures
	
	To reproduce statistics:
		1. run compute_statistics_and_secondary_results.py
		2. Use an IDE (my preference is Spyder) to look through the variables that are produced ind the 
		   'main' section at the bottom of the script
		
    To reproduce processing of DLC+Anipose trajectories, then figures and statistics:
		1. In dlc_anipose_and_xromm_trajectory_and_secondary_data_processing_and_analysis.py, 
		   change the 'mode' variable to adjust which of the three analyses you want to do.
		2. Either change the 'load_type' variable to 'pickle' in the figures and stats scripts 
		   described above, or run convert_pickle_to_h5_and_csv.py to convert pickle outputs of 
		   this code to h5.
		3. Reproduce figures and stats as above
	
	To load and view results without running other scripts:
		1. Run load_hdf_to_original_formats.py in an IDE like Spyder
		2. Look thru variables of type array, class, DataFrame, and list
	
	If you wish to start from scratch doing an anipose parameter sweep, running anipose 
	on multiple training sets etc, take a look at the following code:
		1. run_anipose_on_multiple_training_set_sizes.py
		2. run_anipose_parameter_sweep.py
		3. train_networks_to_test_effect_of_training_set_sizes.py
		4. dlc_validation_paper_calibration_and_triangulation.py contains details on calibration methods
	
	If you just want to convert DLC/anipose calibration to mayaCam format, use:
		convert_anipose_calibration_to_mayaCam.py
	
3. Instrument- or software-specific information needed to interpret the data: 
	Python 3 (we used python 3.8), Spyder or another IDE, and the following modules:
    	pickle
		dill
		pandas
		numpy
		os
		glob
		statsmodels
		sklearn
		inspect
		h5py
		scipy
		itertools
		matplotlib
		seaborn
		cv2

4. Code also available at https://github.com/hatsopoulos-lab/marmoset-dlc_xromm_validation

5. People involved with sample collection, processing, analysis and/or submission: 
    Dalton Moore      (University of Chicago)
    Jeffrey Walker    (University of Chicago)
    Jason MacLean     (University of Chicago)
    Nicho Hatsopoulos (University of Chicago)
